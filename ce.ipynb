{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from typing import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, reduction: Literal['mean', 'sum', 'none'] = 'mean', ignore_index: int = -1, num_classes: int = 256):\n",
    "        super().__init__()\n",
    "        self.reduction = reduction\n",
    "        self.ignore_index = ignore_index\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "\n",
    "    def forward(self, outputs: torch.Tensor, targets: torch.Tensor):\n",
    "        targets = torch.where(targets == self.ignore_index, torch.zeros_like(targets, dtype=torch.int), targets)\n",
    "        x_exp = torch.sum(outputs * F.one_hot(targets, num_classes=self.num_classes).float(), dim=-1).exp()\n",
    "        x_sum = outputs.exp().sum(dim=-1, keepdim=True)\n",
    "        loss = -torch.log(x_exp / x_sum)\n",
    "\n",
    "        if self.reduction != 'none':\n",
    "            loss = loss[torch.where(targets != self.ignore_index)]\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ce_loss():\n",
    "    ce = CrossEntropyLoss(ignore_index=1, reduction='mean')\n",
    "    ce_nn = nn.CrossEntropyLoss(ignore_index=1, reduction='mean')\n",
    "\n",
    "    bs, seqlen, n_classes = 16, 16, 256\n",
    "\n",
    "    for i in range(10):\n",
    "        outputs = torch.rand(bs, seqlen, n_classes)\n",
    "        targets = torch.randint(0, n_classes, (bs, seqlen))\n",
    "\n",
    "        loss = ce(outputs.view(-1, n_classes), targets.view(-1))\n",
    "        loss_nn = ce_nn(outputs.view(-1, n_classes), targets.view(-1))\n",
    "\n",
    "        assert torch.allclose(loss, loss_nn, rtol=1e-3, atol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ce_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ce_loss_multiclass():\n",
    "    output = torch.randn(16, 16, 256)\n",
    "    onehot = torch.zeros_like(output)\n",
    "    onehot[:, :, output.argmax(-1)] = 1\n",
    "    loss_fn = CrossEntropyLoss()\n",
    "    \n",
    "    losses = []\n",
    "    for alpha in range(0, 1.1, 0.1):\n",
    "        target = torch.lerp(onehot, output, alpha)\n",
    "        loss = loss_fn(output, target)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    assert losses == sorted(losses, reverse=True)\n",
    "    assert losses[-1] == 0\n",
    "    assert losses[0] > 0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "attn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
